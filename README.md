项目论述

本项目的核心前提是：大型语言模型（LLM）在计算本质上是一个将输入字符串（或token串）映射到输出字符串的（或者说一个字符串生成器的）函数。例如，给定输入“翻译：Hello”，输出“你好”。

因此，项目的目标并非提升其拟人化的对话能力，而是探索如何利用其字符串映射特性进行“语义编程”。语义编程就是指通过提示词这一字符串，引导模型执行特定的计算任务。（这和lisp的code is data，data is code有相通之处）（再看得广一些，这和中心法则（DNA⇔RNA→蛋白质——但是RNA既可以存信息也可以进行催化）也有相似之处。）

然而，为每一个计算任务人工编写提示词是不可行的。一个自然的想法是让模型自身来生成提示词。但这将导致一个根本性问题：模型在生成提示词时，其内部固有的知识分布会被输入字符串激活，并主导后续输出，从而覆盖外部输入的真实意图，产生系统幻觉。例如，让模型总结一篇它不熟悉的技术论文，它可能转而生成一篇基于其常识的、而非基于论文内容的总结。

为解决系统幻觉，我们必须通过架构设计，最小化LLM内部知识在计算中的贡献。具体方法是约束LLM的行为，使其主要对外部输入字符串进行存储、压缩和重组。在此模式下，LLM更倾向于展现基于输入的语义计算，例如，从输入文本中精确提取实体关系，而非调用内部知识进行联想。近似地，这可以看作将LLM用作一个可编程的语义运算符。

但此约束并非没有代价。它提升了系统在目标任务上的可靠性，却可能使其在面对某些针对性攻击时更为脆弱，例如精心设计的提示词注入。这类似于“没有免费午餐定理”所揭示的规律：不存在一种优化器在所有可能问题上都表现最佳。我们通过接受在特定对抗性场景下的弱点，来换取在目标场景下的鲁棒性。

单个被约束的LLM节点能力有限。因此，系统需要网络化。如果让LLM能够自主操作其在网络中的连接，例如，根据信息流价值动态建立或切断与其他节点的连接，那么将促进角色的自举性生成。这相当于在单个上下文窗口内，为LLM提供了具身性的输入输出体验。

进一步地，如果将整个网络视为一个整体，那么通过恰当的连接设计，节点之间可以相互校验与补充。理论上，一个网络的整体行为可以抵消个体LLM的内部知识偏见，从而实现一种完全依赖外部经验输入的学习与行为模式。例如，一个节点基于片面信息做出的错误推断，可能被另一个拥有不同信息源的节点纠正。

然而，网络自身面临着优化问题：如何动态调整其结构与信息流以达到更优状态？我们认为，LLM本身可以被用作优化器。这里的优化并非指让LLM优化其自身的模型权重，而是让LLM对描述系统状态的输入字符串进行运算，输出优化的配置字符串——例如，更有效的提示词或连接指令。这本质上是将LLM用于元编程。

基于以上论述，我们应实现一个思维模式的转变：从“提示词 -> 模型 -> 生成内容”的范式，转向“非结构化信息 -> 模型 -> 非结构化信息”的范式。前者的实例是生成代码、创作故事，其过程强烈依赖模型内部知识；后者的实例是翻译、信息提取、摘要，其过程更依赖输入信息，因而更可控、更可靠。Transformer模型在前者表现出色但易生幻觉，在后者则近乎不会出错。

为了验证上述理论，我们构建了一个多智能体系统。该系统由多个LLM实例构成，每个实例都被一段严格的预提示词编程为一个“语义处理器”。系统核心组件包括：

· 消息总线：负责在智能体间路由字符串。
· 智能体：具备状态、输入/输出连接和缓存，其核心行为被约束为：接收消息、更新状态、发送消息与信号。
· 信号系统：允许智能体通过特定字符串指令操作网络连接，例如SEEK（寻找新连接）、SPLIT（分裂智能体以实现功能专化）。

当前，项目已完成基础框架构建，并进行了单智能体测试。测试场景为互动小说游戏，核心挑战是克服模型的“选择性记忆”倾向。通过迭代优化预提示词，我们强制智能体在其状态中像写日记一样记录详尽的情景细节，而非仅概括“重点”。实验表明，单节点在记忆广度上存在瓶颈。

接下来，我们将扩展为真正的网络。计划引入分布式的、带有噪声的信息流，例如联网搜索获取的实时信息，以测试网络是否能够通过节点协作，在整体上实现更强大的记忆与噪声抵消能力。我们最终的关键实验是：让系统分析其自身运行时产生的日志，观察其能否自发地识别出日志所记录的系统即是其自身。为维持系统在无外界输入时的活性，我们将引入一个具备自激活能力的驱动智能体。

本项目的最终目的，是观察一个在严格约束下、依赖经验输入的系统，其智能行为能否从可靠的计算中自然涌现，并最终达成对自身的认知。
